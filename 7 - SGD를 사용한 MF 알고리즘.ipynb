{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movieLens 100K 데이터 불러오기\n",
    "* u.data : 영화평가(rating) 데이터\n",
    "    * user_id : 사용자 id\n",
    "    * movie_id : 영화 id\n",
    "    * rating : 평점 (1~5)\n",
    "    * timestamp : 평가한 연도/날짜/시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./Data/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set의 비율 75%, test set의 비율 25%\n",
    "TRAIN_SIZE = 0.75\n",
    "# 데이터를 무작위로 섞는다.\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New MF class for training & testing\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        # user_id, item_id를 R의 index와 매핑하기 위한 dictionary 생성 과정\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "\n",
    "        # num_users : 사용자 수, num_items(아이템 수)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        # K : 잠재요인(Latent Fector)의 수\n",
    "        self.K = K\n",
    "        # alpha : Learning Rate\n",
    "        self.alpha = alpha\n",
    "        # beta : 정규화 계수\n",
    "        self.beta = beta\n",
    "        # iterations : 반복 횟수\n",
    "        self.iterations = iterations\n",
    "        # verbose : 중간 학습과정 출력 여부\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    # 현재의 P와 Q를 가지고 Root Mean Squared Error (RMSE) 계산\n",
    "    def rmse(self):\n",
    "        # 평점이 있는(0이 아닌) 요소의 인덱스\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            # 사용자 x, 아이템 y에 대해서 평점 예측치를 get_prediction()함수를 사용하여 계산\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            # 계산된 평점과 실제 값간의 오차를 errors리스트에 추가\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        # RMSE를 계산하여 반환\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        # 분리된 test set을 넘겨받아 클래스 내부의 test_set을 만드는 함수\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):      # test 데이터에 있는 각 데이터에 대해서\n",
    "            # 현재 사용자의 인덱스를 user_id_index에서 받아온다.\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            # 현재 아이템의 인덱스를 item_id_index에서 받아온다.\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            # 현재 사용자-아이템의 평점\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            # (사용자, 아이템, 평점)을 test_set에 추가\n",
    "            test_set.append([x, y, z])\n",
    "            # R을 사용해서 MF 모델을 학습하기 떄문에 test_set의 R을 제거\n",
    "            self.R[x, y] = 0                    # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set                         # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        # test set에 있는 각각의 (사용자, 아이템, 평점)에 대해서 RMSE를 구한다.\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50\n",
      "Iteration: 100 ; Train RMSE = 0.9013 ; Test RMSE = 0.9423\n",
      "Iteration: 200 ; Train RMSE = 0.7503 ; Test RMSE = 0.9159\n",
      "Iteration: 300 ; Train RMSE = 0.5544 ; Test RMSE = 0.9381\n",
      "K = 60\n",
      "Iteration: 100 ; Train RMSE = 0.9048 ; Test RMSE = 0.9436\n",
      "Iteration: 200 ; Train RMSE = 0.7615 ; Test RMSE = 0.9180\n",
      "Iteration: 300 ; Train RMSE = 0.5499 ; Test RMSE = 0.9361\n",
      "K = 70\n",
      "Iteration: 100 ; Train RMSE = 0.9053 ; Test RMSE = 0.9433\n",
      "Iteration: 200 ; Train RMSE = 0.7674 ; Test RMSE = 0.9169\n",
      "Iteration: 300 ; Train RMSE = 0.5485 ; Test RMSE = 0.9312\n",
      "K = 80\n",
      "Iteration: 100 ; Train RMSE = 0.9064 ; Test RMSE = 0.9434\n",
      "Iteration: 200 ; Train RMSE = 0.7736 ; Test RMSE = 0.9145\n",
      "Iteration: 300 ; Train RMSE = 0.5523 ; Test RMSE = 0.9250\n",
      "K = 90\n",
      "Iteration: 100 ; Train RMSE = 0.9070 ; Test RMSE = 0.9434\n",
      "Iteration: 200 ; Train RMSE = 0.7822 ; Test RMSE = 0.9153\n",
      "Iteration: 300 ; Train RMSE = 0.5568 ; Test RMSE = 0.9239\n",
      "K = 100\n",
      "Iteration: 100 ; Train RMSE = 0.9080 ; Test RMSE = 0.9438\n",
      "Iteration: 200 ; Train RMSE = 0.7855 ; Test RMSE = 0.9154\n",
      "Iteration: 300 ; Train RMSE = 0.5573 ; Test RMSE = 0.9215\n",
      "K = 110\n",
      "Iteration: 100 ; Train RMSE = 0.9088 ; Test RMSE = 0.9441\n",
      "Iteration: 200 ; Train RMSE = 0.7916 ; Test RMSE = 0.9171\n",
      "Iteration: 300 ; Train RMSE = 0.5612 ; Test RMSE = 0.9231\n",
      "K = 120\n",
      "Iteration: 100 ; Train RMSE = 0.9091 ; Test RMSE = 0.9440\n",
      "Iteration: 200 ; Train RMSE = 0.7936 ; Test RMSE = 0.9157\n",
      "Iteration: 300 ; Train RMSE = 0.5605 ; Test RMSE = 0.9201\n",
      "K = 130\n",
      "Iteration: 100 ; Train RMSE = 0.9095 ; Test RMSE = 0.9442\n",
      "Iteration: 200 ; Train RMSE = 0.7974 ; Test RMSE = 0.9168\n",
      "Iteration: 300 ; Train RMSE = 0.5673 ; Test RMSE = 0.9198\n",
      "K = 140\n",
      "Iteration: 100 ; Train RMSE = 0.9096 ; Test RMSE = 0.9439\n",
      "Iteration: 200 ; Train RMSE = 0.8025 ; Test RMSE = 0.9158\n",
      "Iteration: 300 ; Train RMSE = 0.5720 ; Test RMSE = 0.9174\n",
      "K = 150\n",
      "Iteration: 100 ; Train RMSE = 0.9103 ; Test RMSE = 0.9442\n",
      "Iteration: 200 ; Train RMSE = 0.8058 ; Test RMSE = 0.9167\n",
      "Iteration: 300 ; Train RMSE = 0.5760 ; Test RMSE = 0.9159\n",
      "K = 160\n",
      "Iteration: 100 ; Train RMSE = 0.9104 ; Test RMSE = 0.9443\n",
      "Iteration: 200 ; Train RMSE = 0.8096 ; Test RMSE = 0.9177\n",
      "Iteration: 300 ; Train RMSE = 0.5795 ; Test RMSE = 0.9184\n",
      "K = 170\n",
      "Iteration: 100 ; Train RMSE = 0.9106 ; Test RMSE = 0.9442\n",
      "Iteration: 200 ; Train RMSE = 0.8109 ; Test RMSE = 0.9164\n",
      "Iteration: 300 ; Train RMSE = 0.5851 ; Test RMSE = 0.9156\n",
      "K = 180\n",
      "Iteration: 100 ; Train RMSE = 0.9109 ; Test RMSE = 0.9444\n",
      "Iteration: 200 ; Train RMSE = 0.8144 ; Test RMSE = 0.9177\n",
      "Iteration: 300 ; Train RMSE = 0.5857 ; Test RMSE = 0.9153\n",
      "K = 190\n",
      "Iteration: 100 ; Train RMSE = 0.9111 ; Test RMSE = 0.9444\n",
      "Iteration: 200 ; Train RMSE = 0.8160 ; Test RMSE = 0.9177\n",
      "Iteration: 300 ; Train RMSE = 0.5909 ; Test RMSE = 0.9157\n",
      "K = 200\n",
      "Iteration: 100 ; Train RMSE = 0.9113 ; Test RMSE = 0.9444\n",
      "Iteration: 200 ; Train RMSE = 0.8190 ; Test RMSE = 0.9179\n",
      "Iteration: 300 ; Train RMSE = 0.5943 ; Test RMSE = 0.9131\n",
      "K = 210\n",
      "Iteration: 100 ; Train RMSE = 0.9114 ; Test RMSE = 0.9445\n",
      "Iteration: 200 ; Train RMSE = 0.8202 ; Test RMSE = 0.9184\n",
      "Iteration: 300 ; Train RMSE = 0.5973 ; Test RMSE = 0.9147\n",
      "K = 220\n",
      "Iteration: 100 ; Train RMSE = 0.9114 ; Test RMSE = 0.9444\n",
      "Iteration: 200 ; Train RMSE = 0.8214 ; Test RMSE = 0.9179\n",
      "Iteration: 300 ; Train RMSE = 0.6007 ; Test RMSE = 0.9139\n",
      "K = 230\n",
      "Iteration: 100 ; Train RMSE = 0.9116 ; Test RMSE = 0.9444\n",
      "Iteration: 200 ; Train RMSE = 0.8231 ; Test RMSE = 0.9180\n",
      "Iteration: 300 ; Train RMSE = 0.6032 ; Test RMSE = 0.9134\n",
      "K = 240\n",
      "Iteration: 100 ; Train RMSE = 0.9118 ; Test RMSE = 0.9446\n",
      "Iteration: 200 ; Train RMSE = 0.8260 ; Test RMSE = 0.9189\n",
      "Iteration: 300 ; Train RMSE = 0.6053 ; Test RMSE = 0.9135\n",
      "K = 250\n",
      "Iteration: 100 ; Train RMSE = 0.9119 ; Test RMSE = 0.9446\n",
      "Iteration: 200 ; Train RMSE = 0.8282 ; Test RMSE = 0.9190\n",
      "Iteration: 300 ; Train RMSE = 0.6087 ; Test RMSE = 0.9131\n",
      "K = 260\n",
      "Iteration: 100 ; Train RMSE = 0.9121 ; Test RMSE = 0.9446\n",
      "Iteration: 200 ; Train RMSE = 0.8297 ; Test RMSE = 0.9195\n",
      "Iteration: 300 ; Train RMSE = 0.6120 ; Test RMSE = 0.9128\n"
     ]
    }
   ],
   "source": [
    "# 최적의 K값 찾기\n",
    "results = []\n",
    "index = []\n",
    "for K in range(50, 261, 10):\n",
    "    print('K =', K)\n",
    "    R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "    mf = NEW_MF(R_temp, K=K, alpha=0.001, beta=0.02, iterations=300, verbose=True)\n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 iterations 값 찾기\n",
    "summary = []\n",
    "for i in range(len(results)):\n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j+1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K에 따른 RMSE 그래프\n",
    "plt.plot(index, [x[2] for x in summary])\n",
    "plt.ylim(0.89, 0.94)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 ; Train RMSE = 0.9112 ; Test RMSE = 0.9444\n",
      "Iteration: 200 ; Train RMSE = 0.8173 ; Test RMSE = 0.9176\n",
      "[[3.53780618 3.17527362 3.00182095 ... 3.13186941 3.44279628 3.41034445]\n",
      " [3.80292465 3.39419002 3.01061765 ... 3.2774658  3.55333998 3.53185167]\n",
      " [3.49186469 2.8759052  2.57731216 ... 2.69800249 2.97644451 2.96144595]\n",
      " ...\n",
      " [4.24018646 3.79025141 3.53169452 ... 3.61682061 3.90450393 3.88497407]\n",
      " [4.66215159 4.02020744 3.61504046 ... 3.65319004 3.95507616 3.92863857]\n",
      " [4.02443555 3.59354924 2.95757597 ... 3.09778579 3.41519217 3.38144783]]\n",
      "3.1752736165931346\n"
     ]
    }
   ],
   "source": [
    "# 최적의 K와 iteration으로 모델 학습\n",
    "RMSES = []\n",
    "for K, iteration, RMSE in summary:\n",
    "    RMSES.append(RMSE)\n",
    "min = np.min(RMSES)\n",
    "j = RMSES.index(min)\n",
    "optimal_K = summary[j][0]\n",
    "optimal_iteration = summary[j][1]\n",
    "\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=optimal_K, alpha=0.001, beta=0.02, iterations=optimal_iteration, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()\n",
    "\n",
    "# Printing predictions\n",
    "print(mf.full_prediction())\n",
    "print(mf.get_one_prediction(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
